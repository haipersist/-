# 安全性问题的由来

&#x20;     应用程序在运行时，所需要的指令和数据会存储在内存中（只是在需要时被加载，否则还是在磁盘中，这里涉及到虚拟内存的概念，暂时不做过多阐述），CPU在执行时首先要从内存中取出，随后再经过译码，执行等过程。在整个过程中，最浪费时间的就是从内存中取指令的过程，通常需要几十个，甚至上百个时钟周期。因此，为了解决CPU处理速度和从内存中读写数据的速率不匹配的问题，在CPU和内存之间加入了高速缓存，以便能够加快CPU读写数据的速度。

在早期，只引入了L1和L2两层高速缓存，随后又引入了L3。其中L1层又分成指令缓存和数据缓存，L2和L3不区分；L1和L2是单核处理器独有的，L3是所有处理器共享的一层。下面示意图展示了一个8核（注意这里说的是物理，不是逻辑的）处理器的缓存结构：

![](https://p3-sign.toutiaoimg.com/tos-cn-i-qvj2lq49k0/d820db4fc95b49e185f598c980da5e55\~noop.image?\_iz=58558\&from=article.pc\_detail\&x-expires=1664882458\&x-signature=bqi9dIldx3wYfbLFfNSNqguGL8A%3D)

CPU Cache

引入缓存之后，CPU首先从L1中读取数据，如果有则直接返回；如果没有再到L2中读取；如果没有再到L3中读取；如果还没有则再到主内存中读取，随后将目标数据或指令写入到高速缓存中。其中离CPU越近的高速缓存其读取性能就越好，但是其容量也就越小，因此通过设置多级缓存来达到容量和速度的一个平衡。

通过引入高速缓存，可以大大提升读取速度。而之所以高速缓存会提升读取性能，主要得益于所采用的存储技术，比如主存通常使用的DRAM，缓存通常使用SRAM，两种是不同的随机存储技术，这里不做过多阐述。此外，cache利用了程序的局部性原理，可以提前加载数据到内存（预读），局部性包括时间局部性和空间局部性。时间局部性是指同一个数据被访问之后很有可能再次被访问；空间局部性是指被访问的数据附近的位置也有可能被访问。

上面提到了数据会从主存中加载到缓存，那是如何加载的，是一次性加载到内存中吗？还是一个字节一个字节读取？

实际上，数据是按照一个基本单元读取的，大小通常为64字节，叫做缓存行（Cache Line)，每次可能会更新多个缓存行。每层Cache也是由多个CacheLine组成。假如现在有一个long型数组 long\[] data，长度为50。由于long型为8字节，那么data\[0]-data\[7]会在同一个缓存行中加载，每个cache line包括tag，数据块和flag三个部分。如果在读取时可以直接从高速缓存中读取，可以大大提高性能。我们在平时的代码编写的时候也应该充分利用cache line。不同的代码可能带来的性能是不一样的。这里举个例子，现在有个需求是计算二维数组的总和。下面是两段不同的执行代码：

代码1：

```
 public long calSum(long[][] longArray){
        long sum = 0;
        for (int i=0;i++<longArray.length;){
           //按照行读取
            for (int j=0;j++<longArray[i].length;){
                sum += longArray[i][j];
            }
        }
        return sum;
    }
```

代码二：

```
public long calSum(long[][] longArray){
        long sum = 0;
        long columLegth = longArray[0].length;
        for (int j=0;j++<columLegth;){
           //按照列读取
            for (int i=0;i++<longArray.length;){
                sum += longArray[i][j];
            }
        }
        return sum;
    }
```

代码1执行速度要快于代码2.原因就在于缓存是按照行存储的，代码1是按照行遍历，因此更有可能命中缓存；代码2是按照列遍历的，违背了空间局部性的原理。

**伪共享**

上面提到了加载缓存数据是按照CacheLine加载的，如果多个线程访问的数据在同一个缓存行中，且多个线程都试着修改数据，当有个线程成功修改了缓存行中的数据，那么就会将CacheLine置为无效（这个在后面一致性的章节会提到），这就导致其他线程还要从主存中加载数据，从而影响性能，这种现象就叫伪共享。

伪共享可以说是并发编程中的一大隐形bug（叫做隐形杀手可能更合适，因为这不是谁的bug，只是程序可能没有充分利用好计算机的缓存机制）。对于这种现象，其实是可以避免的。比如对于不足64字节的，可以进行字节填充，如long型变量，是8字节，可以在后面补充上7个long型，组成64字节。这在早期的java中也是唯一的解决伪共享的方式，后期引入了Contended注解，该注解可以用在类或者字段上，被该注解装饰的会自动完成字节填充。
